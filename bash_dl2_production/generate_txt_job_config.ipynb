{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b62f537-ad8a-4ba3-bc6f-0fdf157e236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import pickle, json, sys, os, glob\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, os.path.join(\"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/scripts\"))\n",
    "import auxiliar as aux\n",
    "import geometry as geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d4b6d-3d3b-4da8-ae53-b461f4cbc092",
   "metadata": {},
   "source": [
    "# Configuration and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b46fab-a3e2-4021-8be6-d4791fd3edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source specifications\n",
    "source_name = \"crab\"\n",
    "\n",
    "# Run numbers\n",
    "runs = [6172, 3954, 4028, 6853, 6194]\n",
    "\n",
    "create_run_night_dict = False\n",
    "\n",
    "sampling_number = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bb991b-447e-4c3d-9a1c-fe9a53cf4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path of this script\n",
    "root = \"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/dl2_production/\"\n",
    "# Objects path\n",
    "dir_objects = root + \"objects\"\n",
    "# Root path to datachecks\n",
    "dcheck_root = \"/fefs/aswg/workspace/abelardo.moralejo/data/datachecks/night_wise/DL1_datacheck_\"\n",
    "# Config filename for launching the bash script\n",
    "jobconfig_fname = \"jobconfig.txt\"\n",
    "\n",
    "# Creating the directories in case they don't exist\n",
    "for path in [dir_objects]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(os.path.join(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88052756",
   "metadata": {},
   "source": [
    "# Datacheck run-night information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6b0132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if create_run_night_dict:\n",
    "    \n",
    "    dchecks = glob.glob(dcheck_root + \"*.h5\")\n",
    "    \n",
    "    dict_night_run = {}\n",
    "    for i, dcheck in enumerate(dchecks):\n",
    "        if i % 23 == 0:\n",
    "            print(f\"{i}/{len(dchecks)}\")\n",
    "\n",
    "        night = dcheck.split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "        runs = np.unique(pd.read_hdf(dcheck, key=\"runsummary\")[\"runnumber\"])\n",
    "        for run in runs:\n",
    "            dict_night_run[run] = night\n",
    "\n",
    "    # Saving the objects\n",
    "    with open(dir_objects + \"/run_night_dictionary.pkl\", 'wb') as f:\n",
    "        pickle.dump(dict_night_run, f, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(dir_objects + \"/run_night_dictionary.pkl\", 'rb') as f:\n",
    "        dict_night_run = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12373c42-5bb8-439e-8fce-1b068fa4cd17",
   "metadata": {},
   "source": [
    "# Read datacheck light yield data and write it to a job summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989e25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(jobconfig_fname, \"w\")\n",
    "file.write(\"# Job configuration file\\n# RUN_INDEX-RUN-SUBRUN-light yields scaling factors applied\")\n",
    "\n",
    "for i, run in enumerate(runs):\n",
    "\n",
    "    dcheck = dcheck_root + dict_night_run[run] + \".h5\"\n",
    "\n",
    "    tab = pd.read_hdf(dcheck, key=\"cosmics_intensity_spectrum\").query(f\"runnumber == {run}\")\n",
    "    \n",
    "    for srun in np.array(tab[\"subrun\"]):\n",
    "        \n",
    "        light_scaling_factor = 1 / tab.iloc[srun][\"light_yield\"]\n",
    "        \n",
    "        file.write(f\"\\n{i}-{run}-{srun}-{1.}\")\n",
    "        file.write(f\",{light_scaling_factor}\")\n",
    "        \n",
    "        for scale in np.linspace(light_scaling_factor - 0.4, light_scaling_factor + 0.15, sampling_number):\n",
    "            file.write(f\",{scale}\")\n",
    "\n",
    "file.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
