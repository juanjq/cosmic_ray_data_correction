{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c06d147-c1a4-4b4f-8395-2b18ed5f4b36",
   "metadata": {},
   "source": [
    "### Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa942be9-ac39-4184-bd2e-4ff583ab57b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle, sys, os, json\n",
    "import astropy.units as u\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from astropy.coordinates import SkyCoord\n",
    "from matplotlib.dates    import DayLocator, MonthLocator, DateFormatter\n",
    "from regions             import PointSkyRegion\n",
    "from astropy.time        import Time\n",
    "from scipy.stats         import chi2\n",
    "from IPython.display     import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from gammapy.modeling.models import create_crab_spectral_model, SkyModel, LogParabolaSpectralModel\n",
    "from gammapy.estimators      import FluxPointsEstimator, LightCurveEstimator, FluxPoints\n",
    "from gammapy.modeling        import Fit\n",
    "from gammapy.datasets        import Datasets, SpectrumDataset\n",
    "from gammapy.makers          import SpectrumDatasetMaker, WobbleRegionsFinder, ReflectedRegionsBackgroundMaker, SafeMaskMaker\n",
    "from gammapy.maps            import MapAxis, RegionGeom, Map, TimeMapAxis\n",
    "from gammapy.data            import DataStore\n",
    "\n",
    "# import scripts\n",
    "sys.path.insert(0, os.path.join(\"/fefs/aswg/workspace/juan.jimenez/lst1_systematics/scripts\"))\n",
    "import auxiliar  as aux\n",
    "import documents as docs\n",
    "\n",
    "# ============================ #\n",
    "# dl3 path where dl3 and index files are\n",
    "# dl3_dir = \"/fefs/aswg/workspace/daniel.morcuende/data/real/DL3/Crab_performance/AllSkyMC_v0.9.9/intensity80/all_nodes/gh_eff_0.7_th_cont_0.7\"\n",
    "dl3_dir = \"/fefs/aswg/workspace/juan.jimenez/data/lst1_systematics/dl3\"\n",
    "\n",
    "fname_dict = \"objects/dict_sed_and_lc.pkl\"\n",
    "# ============================ #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163d520-9469-4c5e-9c0b-c7d0f961153d",
   "metadata": {},
   "source": [
    "### Loading configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028a1ca5-5eac-471e-85cd-cd16f29a954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the configuration from the gammapy configuration file\n",
    "target_name, n_off_regions, _e_reco, _e_true = docs.load_gammapy_analysis_configuration()\n",
    "\n",
    "e_reco_min, e_reco_max, e_reco_bin_p_dec = _e_reco[\"min\"], _e_reco[\"max\"], _e_reco[\"bins_p_dec\"]\n",
    "e_true_min, e_true_max, e_true_bin_p_dec = _e_true[\"min\"], _e_true[\"max\"], _e_true[\"bins_p_dec\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa354a1-2aa6-45ea-83dd-9dea4cdedec0",
   "metadata": {},
   "source": [
    "### Loading full datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d77300-170c-462b-bf2c-7bffdec939bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening all the dl3 data in a path\n",
    "total_data_store = DataStore.from_dir(dl3_dir)\n",
    "\n",
    "# Taking obs ids\n",
    "obs_ids = total_data_store.obs_table[\"OBS_ID\"].data\n",
    "obs_ids = obs_ids[:]\n",
    "\n",
    "# Then we get the observation information from the total data store\n",
    "observations = total_data_store.get_observations(\n",
    "    obs_ids,\n",
    "    required_irf=[\"aeff\", \"edisp\", \"rad_max\"]\n",
    ")\n",
    "\n",
    "# Defining target position and ON reion\n",
    "target_position = SkyCoord.from_name(target_name, frame='icrs')\n",
    "on_region = PointSkyRegion(target_position)\n",
    "\n",
    "print(f'Total livetime of observations {total_data_store.obs_table[\"LIVETIME\"].data.sum()/3600:.2f} h')\n",
    "display(total_data_store.obs_table[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e287538-e24e-406a-9c51-80fa90658e50",
   "metadata": {},
   "source": [
    "### Defining all the energy axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc148f-7dec-4460-ba3f-15be1daf9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ #\n",
    "# estimated energy axes\n",
    "energy_axis = MapAxis.from_energy_bounds(\n",
    "    e_reco_min, e_reco_max, \n",
    "    nbin=e_reco_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\", name=\"energy\"\n",
    ")\n",
    "# ============================ #\n",
    "# estimated energy axes\n",
    "energy_axis_true = MapAxis.from_energy_bounds(\n",
    "    e_true_min, e_true_max, \n",
    "    nbin=e_true_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\", name=\"energy_true\"\n",
    ")\n",
    "# ============================ #\n",
    "# Energy for the spectrum\n",
    "e_fit_min = energy_axis.edges[1].value\n",
    "e_fit_max = energy_axis.edges[-1].value\n",
    "e_fit_bin_p_dec = e_reco_bin_p_dec\n",
    "\n",
    "# Just to have a separate MapAxis for spectral fit energy range\n",
    "energy_fit_edges = MapAxis.from_energy_bounds(\n",
    "    e_fit_min, e_fit_max, \n",
    "    nbin=e_fit_bin_p_dec, per_decade=True, \n",
    "    unit=\"TeV\"\n",
    ").edges\n",
    "\n",
    "# ============================ #\n",
    "# Energy for the lightcurve\n",
    "e_lc_min = energy_axis.edges[0]\n",
    "e_lc_max = energy_axis.edges[-1]\n",
    "\n",
    "print(\"Spectral fit will be done in energy edges:\\n\", energy_fit_edges)\n",
    "print(f\"\\nLC will be estimated from {e_lc_min:.1f} to {e_lc_max:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ae4ca-692e-4bfc-899d-d0bdfb287099",
   "metadata": {},
   "source": [
    "### Getting time parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0eade5-d306-4034-9be9-0feac9c4a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the GTI parameters of each observations to create time intervals for plotting LC\n",
    "# t_start  = []\n",
    "# t_stop   = []\n",
    "# tot_time = []\n",
    "\n",
    "# for obs in observations:\n",
    "#     gti = obs.gti\n",
    "    \n",
    "#     t_start.append( gti.time_start[0])\n",
    "#     t_stop.append(  gti.time_stop[0])\n",
    "#     tot_time.append(gti.time_sum.value)\n",
    "\n",
    "# t_start  = np.sort(np.array(t_start))\n",
    "# t_stop   = np.sort(np.array(t_stop))\n",
    "# tot_time = np.array(tot_time)\n",
    "\n",
    "# t_start = Time(t_start)\n",
    "# t_stop  = Time(t_stop)\n",
    "\n",
    "# t_day = np.unique(np.rint(t_start.mjd))\n",
    "\n",
    "# # To make the range night-wise, keep the MJD range in half integral values\n",
    "# t_range = [Time([t-0.5, t+0.5], format=\"mjd\", scale=\"utc\") for t in t_day]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35686077-d04f-4885-ba22-c9d739998641",
   "metadata": {},
   "source": [
    "### We define the geometry regions in te sky and prepare the empty datasets and makers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b1f96-2ae4-4ed6-8f30-c5d812aa60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometry defining the ON region and SpectrumDataset based on it\n",
    "geom = RegionGeom.create(\n",
    "    region=on_region, \n",
    "    axes=[energy_axis]\n",
    ")\n",
    "\n",
    "# creating an empty dataset\n",
    "dataset_empty = SpectrumDataset.create(\n",
    "    geom=geom, \n",
    "    energy_axis_true=energy_axis_true\n",
    ")\n",
    "dataset_maker = SpectrumDatasetMaker(\n",
    "    containment_correction=False,\n",
    "    selection=[\"counts\", \"exposure\", \"edisp\"]\n",
    ")\n",
    "\n",
    "# tell the background maker to use the WobbleRegionsFinder\n",
    "region_finder = WobbleRegionsFinder(n_off_regions=n_off_regions)\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d22616-6e73-4e0f-a95b-482bee1176c8",
   "metadata": {},
   "source": [
    "### Now we analize the ON and OFF regions in the dataset and we store them in `datasets`, then the datasets can be stacked in a unique one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23ba7c-9963-4aeb-b833-eccc15664fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# The final object will be stored as a Datasets object\n",
    "datasets = Datasets()\n",
    "\n",
    "for observation in observations:\n",
    "    dataset = dataset_maker.run(\n",
    "        dataset=dataset_empty.copy(name=str(observation.obs_id)),\n",
    "        observation=observation\n",
    "    )\n",
    "    dataset_on_off = bkg_maker.run(\n",
    "        dataset=dataset, \n",
    "        observation=observation\n",
    "    )\n",
    "    datasets.append(dataset_on_off) \n",
    "\n",
    "# Stacking all the datasets in one\n",
    "stacked_dataset = Datasets(datasets).stack_reduce()\n",
    "print(stacked_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407286a-7e1a-41f9-a2d6-d7d798e5538b",
   "metadata": {},
   "source": [
    "### Then we define the model and set inside the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0bca34-b9e7-43bb-a3ac-56b65fc52bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model we want to fit and the starting values\n",
    "spectral_model = LogParabolaSpectralModel(\n",
    "    amplitude=1e-12 * u.Unit(\"cm-2 s-1 TeV-1\"),\n",
    "    alpha=2,\n",
    "    beta=0.1,\n",
    "    reference=1 * u.TeV,\n",
    ")\n",
    "# we will use the crab model in general\n",
    "model = SkyModel(\n",
    "    spectral_model=spectral_model, \n",
    "    name=\"crab\"\n",
    ")\n",
    "\n",
    "# We set the model of all datasets to log parabola\n",
    "stacked_dataset.models = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e5e56b",
   "metadata": {},
   "source": [
    "### We fit the model with the stacked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695148b7-e285-4fac-a9ff-7094988b47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Now we run the fit to extract the parameters of the model\n",
    "fit = Fit()\n",
    "result = fit.run(datasets=stacked_dataset)\n",
    "best_fit_model = model.copy()\n",
    "\n",
    "display(stacked_dataset.models.to_parameters_table())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b97bc",
   "metadata": {},
   "source": [
    "### Then from the model and the data we can extract the flux points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1fd7e-2228-4ccd-ae99-c0992bf28228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# then extracting the flux points from the data\n",
    "fpe = FluxPointsEstimator(\n",
    "    energy_edges=energy_fit_edges, \n",
    "    source=target_name, \n",
    "    selection_optional=\"all\"\n",
    ")\n",
    "\n",
    "# We apply the flux point estiation from the datasets\n",
    "flux_points = fpe.run(datasets=stacked_dataset)\n",
    "flux_points.to_table(sed_type=\"dnde\", formatted=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51809436-e823-4321-8094-ecdb47e0c9c0",
   "metadata": {},
   "source": [
    "### Then we can plot the SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1305bcb-6268-45ed-954b-12ceeca5f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {\n",
    "    \"energy_bounds\": [0.08, 100] * u.TeV,\n",
    "    \"sed_type\": \"e2dnde\",\n",
    "    \"yunits\": u.Unit(\"TeV cm-2 s-1\"),\n",
    "    \"xunits\": u.TeV,\n",
    "}\n",
    "\n",
    "# Crab models\n",
    "crab_magic_100 = create_crab_spectral_model(\"magic_lp\")\n",
    "crab_magic_10  = create_crab_spectral_model(\"magic_lp\")\n",
    "crab_magic_1   = create_crab_spectral_model(\"magic_lp\")\n",
    "crab_magic_10.amplitude.value = crab_magic_10.amplitude.value * 0.1\n",
    "crab_magic_1.amplitude.value  = crab_magic_1.amplitude.value  * 0.01\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "\n",
    "best_fit_model.spectral_model.plot(\n",
    "    ax=ax, ls=\"-\", lw=1.5, color=\"k\", label=\"best fit\", **plot_kwargs\n",
    ")\n",
    "\n",
    "best_fit_model.spectral_model.plot_error(\n",
    "    ax=ax, facecolor=\"k\", alpha=0.2, **plot_kwargs\n",
    ")\n",
    "\n",
    "crab_magic_100.plot(\n",
    "    ax=ax, ls=\"--\", lw=1.5, color=\"crimson\", label=\"MAGIC reference (Aleksić et al. 2015)\", **plot_kwargs\n",
    ")\n",
    "# crab_magic_10.plot(\n",
    "#     ax=ax, ls=\"--\", lw=1.5, color=\"crimson\", label=\"Crab 10%\", **plot_kwargs\n",
    "# )\n",
    "# crab_magic_1.plot(\n",
    "#     ax=ax, ls=\"--\", lw=1.5, color=\"crimson\", label=\"Crab 1%\", **plot_kwargs\n",
    "# )\n",
    "\n",
    "flux_points.plot(sed_type=\"e2dnde\", color=\"k\", label=\"Flux points\")\n",
    "flux_points.plot_ts_profiles(sed_type=\"e2dnde\", cmap=cmap)\n",
    "\n",
    "ax.legend(loc=3)\n",
    "ax.set_ylim([1e-13, 1e-10])\n",
    "ax.grid(which=\"both\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc25646-b623-44ff-b85a-3bcf11e21a36",
   "metadata": {},
   "source": [
    "### Then once we have found the SED model we fix the alpha and beta parameters and let the amplitude as a free parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8d703-6c1f-4725-8f09-988867d28070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters[\"alpha\"].frozen = True\n",
    "model.parameters[\"beta\"].frozen  = True\n",
    "\n",
    "# Create the LC Estimator for each run\n",
    "lc_maker_1d = LightCurveEstimator(\n",
    "    energy_edges=[e_lc_min, e_lc_max], \n",
    "    reoptimize=False, # Re-optimizing other free model parameters (not belonging to the source)\n",
    "    source=\"crab\", \n",
    "    selection_optional=\"all\" # Estimates asymmetric errors, upper limits and fit statistic profiles\n",
    ")\n",
    "\n",
    "# Assigning the fixed parameters model to each dataset\n",
    "for data in datasets:\n",
    "    data.models = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780728b6-381a-41d4-985b-0d1cf391d36d",
   "metadata": {},
   "source": [
    "### Then we run the lightcurve maker run-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c871fec-70be-4b0e-99f0-d41b6c963be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"LC will be estimated from {e_lc_min:.1f} to {e_lc_max:.1f}\")\n",
    "\n",
    "lc_runwise = lc_maker_1d.run(datasets)\n",
    "lightcurve = lc_runwise.to_table(sed_type=\"flux\", format=\"lightcurve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1f5c8",
   "metadata": {},
   "source": [
    "### We calculate the mean flux and the statistical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe6d8e-2789-436d-a27b-65e4089ee21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(table, sys_error=0):\n",
    "    val = table[\"flux\"]\n",
    "    uncertainty = np.sqrt((sys_error * table[\"flux\"])**2 + table[\"flux_err\"]**2)\n",
    "    return (val/uncertainty**2).sum() / (1/uncertainty**2).sum(), np.sqrt(1/np.sum(1/uncertainty**2))\n",
    "\n",
    "\n",
    "mean_flux, mean_flux_err = weighted_average(lightcurve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c0309",
   "metadata": {},
   "source": [
    "### Calculating the $\\chi^2$ and $p$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c80d0-5ba2-4971-a7a6-ee0c0c016176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chi2_pvalue(table, sys_error=0):\n",
    "    uncertainty = np.sqrt((sys_error * table[\"flux\"])**2 + table[\"flux_err\"]**2)\n",
    "    flux = table[\"flux\"]\n",
    "    mean_flux = (flux/uncertainty**2).sum() / (1/uncertainty**2).sum()\n",
    "    mean_flux_err = np.sqrt(1/np.sum(1/uncertainty**2))\n",
    "    print(f\"Weighted mean flux: {mean_flux:.3e} +/- {mean_flux_err:.3e} cm-2 s-1\")\n",
    "    \n",
    "    chi2_value = np.sum((table[\"flux\"] - mean_flux)**2/uncertainty**2)\n",
    "    ndf = len(table[\"flux\"]) - 1\n",
    "    pvalue = chi2.sf(x=chi2_value, df=ndf)\n",
    "    print(f\"Chi2: {chi2_value:.1f}, ndf: {ndf}, P-value: {pvalue:.2e}\")\n",
    "    return chi2_value, ndf, pvalue\n",
    "    \n",
    "calculate_chi2_pvalue(lightcurve, sys_error=0.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f74bf8",
   "metadata": {},
   "source": [
    "### Extracting the data from the table as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db199fb7-3cd2-4e47-9c7b-847732a6eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start time, duration and central time\n",
    "time_min = Time(np.hstack(lightcurve[\"time_min\"]), format='mjd').datetime\n",
    "time_max = Time(np.hstack(lightcurve[\"time_max\"]), format='mjd').datetime\n",
    "delta_time  = time_max - time_min\n",
    "time_center = time_min + delta_time / 2\n",
    "\n",
    "# Flux and flux error\n",
    "flux_lst1 = np.hstack(lightcurve[\"flux\"])\n",
    "flux_stat_err_lst1 = np.hstack(lightcurve[\"flux_err\"])\n",
    "\n",
    "# run numbers\n",
    "run_num = [int(n) for n in observations.ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a6f3f",
   "metadata": {},
   "source": [
    "### The Crab Nebula reference from MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11909347-a4dc-42ed-802e-4b0a22665232",
   "metadata": {},
   "outputs": [],
   "source": [
    "crab = create_crab_spectral_model(\"magic_lp\")\n",
    "\n",
    "crab.amplitude.error = 0.03e-11 * u.Unit(\"cm-2 s-1 TeV-1\")\n",
    "crab.alpha.error = 0.01\n",
    "crab.beta.error = 0.01/np.log(10)\n",
    "\n",
    "\n",
    "flux_crab = crab.integral(e_lc_min, e_lc_max)\n",
    "flux_crab_error = flux_crab * 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61fe89",
   "metadata": {},
   "source": [
    "### Plotting the LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cacabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# Plotting the Ligt Curve\n",
    "ax.errorbar(time_center, flux_lst1, yerr=flux_stat_err_lst1, color=\"k\", ls=\"\", marker=\".\", ms=10, label=\"LST-1 (src-independent)\")\n",
    "    \n",
    "# Mean flux + error\n",
    "ax.axhline(mean_flux, ls=\"--\", color=\"k\", zorder=-1, label=\"Mean flux\")\n",
    "ax.axhspan(mean_flux - mean_flux_err, mean_flux + mean_flux_err, color=\"k\", alpha=0.4, zorder=-1)\n",
    "\n",
    "# MAGIC reference\n",
    "ax.axhline(flux_crab.value, ls=\"-.\", color=\"crimson\", zorder=-1, label=\"MAGIC (Aleksić et al. 2015)\")\n",
    "\n",
    "energy_range = f\"{e_lc_min:.1f} < $E$ < {e_lc_max:.1f}\"\n",
    "ax.set_title(f\"Light curve of {target_name} ({energy_range})\")\n",
    "ax.set_ylabel(\"Flux [cm$^{-2}$ s$^{-1}$]\")\n",
    "ax.set_xlabel(\"Time [date]\")\n",
    "ax.grid()\n",
    "ax.legend(loc=4)\n",
    "ax.xaxis.set_major_locator(MonthLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%m-%Y\"))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8868e",
   "metadata": {},
   "source": [
    "### Plotting the LC run-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ed1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,3))\n",
    "\n",
    "# Plotting the Ligt Curve\n",
    "ax.errorbar(np.arange(len(flux_lst1)), flux_lst1, yerr=flux_stat_err_lst1, color=\"k\", ls=\"\", marker=\".\", ms=10, label=\"LST-1 (src-independent)\")  \n",
    "\n",
    "# Mean flux + error\n",
    "ax.axhline(mean_flux, ls=\"--\", color=\"k\", zorder=-1, label=\"Mean flux\")\n",
    "ax.axhspan(mean_flux - mean_flux_err, mean_flux + mean_flux_err, color=\"k\", alpha=0.4, zorder=-1)\n",
    "\n",
    "# MAGIC reference\n",
    "ax.axhline(flux_crab.value, ls=\"-.\", color=\"crimson\", zorder=-1, label=\"MAGIC (Aleksić et al. 2015)\")\n",
    "\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_xlabel(f\"Run #\")\n",
    "ax.set_ylabel(\"Flux [cm$^{-2}$ s$^{-1}$]\")\n",
    "energy_range = f\"{e_lc_min:.1f} < $E$ < {e_lc_max:.1f}\"\n",
    "ax.set_title(f\"Light curve of {target_name} ({energy_range})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebf238",
   "metadata": {},
   "source": [
    "### Now we put all inside a dict and we store it in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d630e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_total = {\n",
    "    \n",
    "    \"dict_model\" : best_fit_model.to_dict(), # SkyModel.from_dict(<>)\n",
    "    \n",
    "    \"table_sed\"  : flux_points.to_table(),   # FluxPoints.from_table(<>)\n",
    "\n",
    "    \"lightcurve\" : {\n",
    "\n",
    "        \"run_number\" : run_num,\n",
    "        \"t_start\"    : time_min,\n",
    "        \"t_stop\"     : time_max,\n",
    "        \"timedelta\"  : delta_time,\n",
    "        \"flux\"       : flux_lst1,\n",
    "        \"e_flux\"     : flux_stat_err_lst1,\n",
    "        \n",
    "        \"global\" : {\n",
    "            \"e_min\" : e_lc_min,\n",
    "            \"e_max\" : e_lc_max,\n",
    "            \"n_off_regions\" : n_off_regions,\n",
    "            \"target_name\"   : target_name\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Saving the object\n",
    "with open(fname_dict, 'wb') as f:\n",
    "    pickle.dump(dict_total, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
