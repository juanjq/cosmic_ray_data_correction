{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cacf4254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from datetime import datetime, timedelta\n",
    "import pickle, json, sys, os, glob\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, os.path.join(\"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/scripts\"))\n",
    "import auxiliar as aux\n",
    "import geometry as geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389bf961",
   "metadata": {},
   "source": [
    "# Paths and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3181ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcheck_root = \"/fefs/aswg/workspace/abelardo.moralejo/data/datachecks/night_wise/DL1_datacheck_\"\n",
    "\n",
    "ws_database = \"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/analysis_first_corrections/objects/WS2003-22_short.h5\"\n",
    "\n",
    "dir_objects = \"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/analysis_weather/objects\"\n",
    "\n",
    "results_path = \"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/bash_weather_data/RESULTS.txt\"\n",
    "\n",
    "create_data_dict = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316af87",
   "metadata": {},
   "source": [
    "# Datachecks information\n",
    "\n",
    "## `cosmics_intensity_spectrum`\n",
    "\n",
    "'yyyymmdd', 'ra_tel', 'dec_tel', 'cos_zenith', 'az_tel', 'runnumber',\n",
    "       'subrun', 'time', 'elapsed_time', 'corrected_elapsed_time',\n",
    "       'cosmics_rate', 'cosmics_cleaned_rate', 'intensity_at_half_peak_rate',\n",
    "       'ZD_corrected_intensity_at_half_peak_rate', 'cosmics_peak_rate',\n",
    "       'ZD_corrected_cosmics_peak_rate', 'cosmics_rate_at_422_pe',\n",
    "       'ZD_corrected_cosmics_rate_at_422_pe', 'cosmics_spectral_index',\n",
    "       'ZD_corrected_cosmics_spectral_index', 'intensity_spectrum_fit_p_value',\n",
    "       'intensity_at_reference_rate', 'diffuse_nsb_std',\n",
    "       'num_star_affected_pixels', 'anomalous_low_intensity_peak'\n",
    "\n",
    "## `runsummary`\n",
    "\n",
    "'runnumber', 'time', 'elapsed_time', 'min_altitude', 'mean_altitude',\n",
    "       'max_altitude', 'min_azimuth', 'max_azimuth', 'mean_azimuth', 'mean_ra',\n",
    "       'mean_dec', 'num_cosmics', 'num_pedestals', 'num_flatfield',\n",
    "       'num_unknown_ucts_trigger_tags', 'num_wrong_ucts_tags_in_cosmics',\n",
    "       'num_wrong_ucts_tags_in_pedestals', 'num_wrong_ucts_tags_in_flatfield',\n",
    "       'num_ucts_jumps', 'num_unknown_tib_trigger_tags',\n",
    "       'num_wrong_tib_tags_in_cosmics', 'num_wrong_tib_tags_in_pedestals',\n",
    "       'num_wrong_tib_tags_in_flatfield', 'num_pedestals_after_cleaning',\n",
    "       'num_contained_mu_rings', 'ff_charge_mean', 'ff_charge_mean_err',\n",
    "       'ff_charge_stddev', 'ff_time_mean', 'ff_time_mean_err',\n",
    "       'ff_time_stddev', 'ff_rel_time_stddev', 'ped_charge_mean',\n",
    "       'ped_charge_mean_err', 'ped_charge_stddev',\n",
    "       'ped_fraction_pulses_above10', 'ped_fraction_pulses_above30',\n",
    "       'cosmics_fraction_pulses_above10', 'cosmics_fraction_pulses_above30',\n",
    "       'mu_effi_mean', 'mu_effi_stddev', 'mu_width_mean', 'mu_width_stddev',\n",
    "       'mu_hg_peak_sample_mean', 'mu_hg_peak_sample_stddev',\n",
    "       'mu_intensity_mean', 'mean_number_of_pixels_nearby_stars'\n",
    "       \n",
    "## Weather Station data\n",
    "\n",
    "'sun_alt', 'sun_az', 'fBits', 'mjd', 'temperature', 'pressure',\n",
    "       'windDirection', 'humidity', 'windSpeedCurrent', 'windGust',\n",
    "       'windSpeedAverage', 'windDirectionAverage', 'tempSensor', 'tngDust',\n",
    "       'tngSeeing', 'rain', 'state', 'Any', 'Mes', 'DP', 'diff1', 'is_dup',\n",
    "       'temperatureR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce73c93",
   "metadata": {},
   "source": [
    "# Extracting dates and parameters of all runs/subruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8cbba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/494\n",
      "10/494\n",
      "20/494\n",
      "30/494\n",
      "40/494\n",
      "50/494\n",
      "60/494\n",
      "70/494\n",
      "80/494\n",
      "90/494\n",
      "100/494\n",
      "110/494\n",
      "120/494\n",
      "130/494\n",
      "140/494\n",
      "150/494\n",
      "160/494\n",
      "170/494\n",
      "180/494\n",
      "190/494\n",
      "200/494\n",
      "210/494\n",
      "220/494\n",
      "230/494\n",
      "240/494\n",
      "250/494\n",
      "260/494\n",
      "270/494\n",
      "280/494\n",
      "290/494\n",
      "300/494\n",
      "310/494\n",
      "320/494\n",
      "330/494\n",
      "340/494\n",
      "350/494\n",
      "360/494\n",
      "370/494\n",
      "380/494\n",
      "390/494\n",
      "400/494\n",
      "410/494\n",
      "420/494\n",
      "430/494\n",
      "440/494\n",
      "450/494\n",
      "460/494\n",
      "470/494\n",
      "480/494\n",
      "490/494\n"
     ]
    }
   ],
   "source": [
    "if create_data_dict:\n",
    "    dchecks = glob.glob(dcheck_root + \"*.h5\")\n",
    "    \n",
    "    \n",
    "    run, srun, time  = [], [], []\n",
    "    telapsed, az, zd = [], [], []\n",
    "    zd_i_a_h_p_r, zd_c_r_a_4, zd_d_c_r_a_4, zd_c_s_i = [], [], [], []\n",
    "    i_a_h_p_r, c_r_a_4, d_c_r_a_4, c_s_i, l_y        = [], [], [], [], []\n",
    "    for i, dcheck in enumerate(dchecks):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(dchecks)}\")\n",
    "\n",
    "        ds = pd.read_hdf(dcheck, key=\"runsummary\")\n",
    "        di = pd.read_hdf(dcheck, key=\"cosmics_intensity_spectrum\")\n",
    "        \n",
    "        for j in range(len(ds)):\n",
    "            runref = ds[\"runnumber\"].iloc[j]\n",
    "            \n",
    "            di_run = di.query(f\"runnumber == {runref}\")\n",
    "            \n",
    "            for k in range(len(di_run)):\n",
    "                \n",
    "                run.append(runref)\n",
    "                srun.append(di[\"subrun\"].iloc[k])\n",
    "                az.append(ds[\"mean_azimuth\"].iloc[j])\n",
    "                zd.append(np.arccos(di[\"cos_zenith\"].iloc[k]))\n",
    "                time.append(datetime.fromtimestamp(di[\"time\"].iloc[k]))\n",
    "                telapsed.append(di[\"corrected_elapsed_time\"].iloc[k])\n",
    "                zd_i_a_h_p_r.append(di[\"ZD_corrected_intensity_at_half_peak_rate\"].iloc[k])\n",
    "                zd_c_r_a_4.append(di[\"ZD_corrected_cosmics_rate_at_422_pe\"].iloc[k])\n",
    "                zd_d_c_r_a_4.append(di[\"ZD_corrected_delta_cosmics_rate_at_422_pe\"].iloc[k])\n",
    "                zd_c_s_i.append(di[\"ZD_corrected_cosmics_spectral_index\"].iloc[k])\n",
    "                i_a_h_p_r.append(di[\"intensity_at_half_peak_rate\"].iloc[k])\n",
    "                c_r_a_4.append(di[\"cosmics_rate_at_422_pe\"].iloc[k])\n",
    "                d_c_r_a_4.append(di[\"delta_cosmics_rate_at_422_pe\"].iloc[k])\n",
    "                c_s_i.append(di[\"cosmics_spectral_index\"].iloc[k])\n",
    "                l_y.append(di[\"light_yield\"].iloc[k])\n",
    "                \n",
    "        \n",
    "    dict_dcheck = {\n",
    "        \"run\" : np.array(run),\n",
    "        \"srun\" : np.array(srun),\n",
    "        \"time\" : np.array(time),\n",
    "        \"telapsed\" : np.array(telapsed),\n",
    "        \"az\" : np.rad2deg(az),\n",
    "        \"zd\" : np.rad2deg(zd),\n",
    "        \"ZD_corrected_intensity_at_half_peak_rate\" : np.array(zd_i_a_h_p_r),\n",
    "        \"ZD_corrected_cosmics_rate_at_422_pe\" : np.array(zd_c_r_a_4),\n",
    "        \"ZD_corrected_delta_cosmics_rate_at_422_pe\" : np.array(zd_d_c_r_a_4),\n",
    "        \"ZD_corrected_cosmics_spectral_index\" : np.array(zd_c_s_i),\n",
    "        \"intensity_at_half_peak_rate\" : np.array(i_a_h_p_r),\n",
    "        \"cosmics_rate_at_422_pe\" : np.array(c_r_a_4),\n",
    "        \"delta_cosmics_rate_at_422_pe\" : np.array(d_c_r_a_4),\n",
    "        \"cosmics_spectral_index\" : np.array(c_s_i),\n",
    "        \"light_yield\" : np.array(l_y)\n",
    "    }\n",
    "            \n",
    "            \n",
    "    # Saving the objects\n",
    "    with open(dir_objects + \"/data_dict.pkl\", 'wb') as f:\n",
    "        pickle.dump(dict_dcheck, f, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(dir_objects + \"/data_dict.pkl\", 'rb') as f:\n",
    "        dict_dcheck = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf641b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ws = pd.read_hdf(ws_database)\n",
    "\n",
    "dates = dict_dcheck[\"time\"][:-3]\n",
    "\n",
    "maxdate = np.max(dates)\n",
    "mindate = np.min(dates)\n",
    "\n",
    "# Assuming df_ws.index is already a NumPy array\n",
    "dates_ws = np.array([datetime.fromisoformat(str(d).split(\".\")[0]) for d in df_ws.index])\n",
    "\n",
    "maxdate_ws = np.max(dates_ws)\n",
    "\n",
    "# Combine date filtering in NumPy\n",
    "mask = (dates_ws > mindate) & (dates_ws < maxdate)\n",
    "dates_ws = dates_ws[mask]\n",
    "df_ws = df_ws[mask]\n",
    "\n",
    "_index_ws   = [int(s.split(\",\")[0]) for s in np.loadtxt(results_path, dtype=str)]\n",
    "_index_data = [int(s.split(\",\")[1]) for s in np.loadtxt(results_path, dtype=str)]\n",
    "\n",
    "_index_ws, _index_data = aux.sortbased(_index_ws, _index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66c5e9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/696142\n",
      "50000/696142\n",
      "100000/696142\n",
      "150000/696142\n",
      "200000/696142\n",
      "250000/696142\n",
      "300000/696142\n",
      "350000/696142\n",
      "400000/696142\n",
      "450000/696142\n",
      "500000/696142\n",
      "550000/696142\n",
      "600000/696142\n",
      "650000/696142\n"
     ]
    }
   ],
   "source": [
    "if create_data_dict:\n",
    "#     df_ws = pd.read_hdf(ws_database)\n",
    "\n",
    "#     dates = dict_dcheck[\"time\"]\n",
    "\n",
    "#     maxdate = np.max(dates)\n",
    "#     mindate = np.min(dates)\n",
    "\n",
    "#     # Assuming df_ws.index is already a NumPy array\n",
    "#     dates_ws = np.array([datetime.fromisoformat(str(d).split(\".\")[0]) for d in df_ws.index])\n",
    "\n",
    "#     maxdate_ws = np.max(dates_ws)\n",
    "        \n",
    "#     # Combine date filtering in NumPy\n",
    "#     mask = (dates_ws > mindate) & (dates_ws < maxdate)\n",
    "#     dates_ws = dates_ws[mask]\n",
    "#     df_ws = df_ws[mask]\n",
    "\n",
    "#     _index_ws   = [int(s.split(\",\")[0]) for s in np.loadtxt(results_path, dtype=str)]\n",
    "#     _index_data = [int(s.split(\",\")[1]) for s in np.loadtxt(results_path, dtype=str)]\n",
    "\n",
    "#     _index_ws, _index_data = aux.sortbased(_index_ws, _index_data)\n",
    "\n",
    "\n",
    "    index_ws, index_data = [], []\n",
    "    for i in range(len((dates))):\n",
    "        \n",
    "        if i < 690675:\n",
    "            date = dates[i]\n",
    "\n",
    "            if date <= maxdate_ws:\n",
    "                index_ws.append(i)\n",
    "            else:\n",
    "                index_ws.append(None)\n",
    "                \n",
    "            index_data.append(_index_data[i])    \n",
    "            \n",
    "        else:\n",
    "            index_ws.append(None)\n",
    "\n",
    "            \n",
    "    \n",
    "    dict_dcheck[\"index_ws\"] = np.array(index_ws)\n",
    "\n",
    "\n",
    "    temperature, pressure, humidity = [], [], []\n",
    "    tngDust, tngSeeing, rain        = [], [], []\n",
    "    for i in range(len(dates)):\n",
    "        if i % 50000 == 0:\n",
    "            print(f\"{i}/{len(dates)}\")\n",
    "        if index_ws[i] != None:\n",
    "            temperature.append(df_ws.iloc[index_ws[i]][\"temperature\"])\n",
    "            pressure.append(df_ws.iloc[index_ws[i]][\"pressure\"])\n",
    "            humidity.append(df_ws.iloc[index_ws[i]][\"humidity\"])\n",
    "            tngDust.append(df_ws.iloc[index_ws[i]][\"tngDust\"])\n",
    "            tngSeeing.append(df_ws.iloc[index_ws[i]][\"tngSeeing\"])\n",
    "            rain.append(df_ws.iloc[index_ws[i]][\"rain\"])\n",
    "        else:\n",
    "            temperature.append(None)\n",
    "            pressure.append(None)\n",
    "            humidity.append(None)\n",
    "            tngDust.append(None)\n",
    "            tngSeeing.append(None)\n",
    "            rain.append(None)\n",
    "\n",
    "    dict_dcheck[\"temperature\"] = np.array(temperature)\n",
    "    dict_dcheck[\"pressure\"]    = np.array(pressure)\n",
    "    dict_dcheck[\"humidity\"]    = np.array(humidity)\n",
    "    dict_dcheck[\"tngDust\"]     = np.array(tngDust)\n",
    "    dict_dcheck[\"tngSeeing\"]   = np.array(tngSeeing)\n",
    "    dict_dcheck[\"rain\"]        = np.array(rain)\n",
    "    \n",
    "    with open(dir_objects + \"/data_dict.pkl\", 'wb') as f:\n",
    "        pickle.dump(dict_dcheck, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
