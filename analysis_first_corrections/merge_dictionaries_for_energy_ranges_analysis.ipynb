{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa942be9-ac39-4184-bd2e-4ff583ab57b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "from astropy.coordinates import SkyCoord\n",
    "import pickle, json, sys, os, glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, os.path.join(\"/fefs/aswg/workspace/juan.jimenez/cosmic_ray_data_correction/scripts\"))\n",
    "import auxiliar as aux\n",
    "import documents as docs\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# =================================== #\n",
    "# paths \n",
    "folder_dict_sed_lc = \"objects/dicts_sed_and_lc\"\n",
    "fname_dict_dl2     = \"objects/dict_dl2.pkl\"\n",
    "\n",
    "folder_total_dicts = \"objects/total_dicts\"\n",
    "\n",
    "energy_ranges_info = \"bash_energy_ranges/jobs_information.txt\"\n",
    "# =================================== #\n",
    "\n",
    "\n",
    "# =================================== #\n",
    "#         intensity profiles\n",
    "# =================================== #\n",
    "\n",
    "# intensity binning\n",
    "binsI = np.linspace(1.1, 4, 200) \n",
    "\n",
    "# =================================== #\n",
    "\n",
    "# load dl2 data\n",
    "with open(fname_dict_dl2, \"rb\") as f:\n",
    "    dict_dl2 = pickle.load(f)\n",
    "    \n",
    "# create folder t do not exist\n",
    "aux.createdir(folder_total_dicts)\n",
    "\n",
    "# extracting LC limits\n",
    "a_lcs = [np.array(s.split(\",\")).astype(float) for s in np.loadtxt(energy_ranges_info, dtype=str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c17dfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating total dict --> dict_total_1.890_50.pkl\n",
      "Creating total dict --> dict_total_1.956_50.pkl\n",
      "Creating total dict --> dict_total_10.000_50.pkl\n",
      "Creating total dict --> dict_total_2.026_50.pkl\n",
      "Creating total dict --> dict_total_2.097_50.pkl\n",
      "Creating total dict --> dict_total_2.171_50.pkl\n",
      "Creating total dict --> dict_total_2.248_50.pkl\n",
      "Creating total dict --> dict_total_2.327_50.pkl\n",
      "Creating total dict --> dict_total_2.409_50.pkl\n",
      "Creating total dict --> dict_total_2.495_50.pkl\n",
      "Creating total dict --> dict_total_2.583_50.pkl\n",
      "Creating total dict --> dict_total_2.674_50.pkl\n",
      "Creating total dict --> dict_total_2.768_50.pkl\n",
      "Creating total dict --> dict_total_2.866_50.pkl\n",
      "Creating total dict --> dict_total_2.967_50.pkl\n",
      "Creating total dict --> dict_total_3.072_50.pkl\n",
      "Creating total dict --> dict_total_3.181_50.pkl\n",
      "Creating total dict --> dict_total_3.293_50.pkl\n",
      "Creating total dict --> dict_total_3.409_50.pkl\n",
      "Creating total dict --> dict_total_3.530_50.pkl\n",
      "Creating total dict --> dict_total_3.654_50.pkl\n",
      "Creating total dict --> dict_total_3.783_50.pkl\n",
      "Creating total dict --> dict_total_3.917_50.pkl\n",
      "Creating total dict --> dict_total_4.055_50.pkl\n",
      "Creating total dict --> dict_total_4.199_50.pkl\n",
      "Creating total dict --> dict_total_4.347_50.pkl\n",
      "Creating total dict --> dict_total_4.501_50.pkl\n",
      "Creating total dict --> dict_total_4.660_50.pkl\n",
      "Creating total dict --> dict_total_4.824_50.pkl\n",
      "Creating total dict --> dict_total_4.995_50.pkl\n",
      "Creating total dict --> dict_total_5.171_50.pkl\n",
      "Creating total dict --> dict_total_5.354_50.pkl\n",
      "Creating total dict --> dict_total_5.543_50.pkl\n",
      "Creating total dict --> dict_total_5.738_50.pkl\n",
      "Creating total dict --> dict_total_5.941_50.pkl\n",
      "Creating total dict --> dict_total_6.151_50.pkl\n",
      "Creating total dict --> dict_total_6.368_50.pkl\n",
      "Creating total dict --> dict_total_6.593_50.pkl\n",
      "Creating total dict --> dict_total_6.826_50.pkl\n",
      "Creating total dict --> dict_total_7.067_50.pkl\n",
      "Creating total dict --> dict_total_7.317_50.pkl\n",
      "Creating total dict --> dict_total_7.575_50.pkl\n",
      "Creating total dict --> dict_total_7.843_50.pkl\n",
      "Creating total dict --> dict_total_8.120_50.pkl\n",
      "Creating total dict --> dict_total_8.407_50.pkl\n",
      "Creating total dict --> dict_total_8.704_50.pkl\n",
      "Creating total dict --> dict_total_9.011_50.pkl\n",
      "Creating total dict --> dict_total_9.329_50.pkl\n",
      "Creating total dict --> dict_total_9.659_50.pkl\n",
      "CPU times: user 46min 45s, sys: 2min 40s, total: 49min 25s\n",
      "Wall time: 49min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fname_dict_sed_lc in np.sort(glob.glob(folder_dict_sed_lc + \"/*\")):\n",
    "\n",
    "    # Energy LC limits\n",
    "    totfname = fname_dict_sed_lc.split(\"/\")[-1].split(\"t_\")[1].split(\".p\")[0]\n",
    "    fname_dict = os.path.join(folder_total_dicts, f\"dict_total_{totfname}.pkl\")\n",
    "    \n",
    "    if not os.path.exists(fname_dict):\n",
    "\n",
    "        print(f\"Creating total dict --> dict_total_{totfname}.pkl\")\n",
    "\n",
    "        # light curve data\n",
    "        with open(fname_dict_sed_lc, \"rb\") as f:\n",
    "            dict_gammapy = pickle.load(f)\n",
    "\n",
    "        dict_LC_run = {}\n",
    "        for i, run in enumerate(np.sort(np.array(dict_gammapy[\"lightcurve\"][\"run_number\"]).astype(int))):\n",
    "\n",
    "            tmp_dict = {\n",
    "\n",
    "                \"flux\"      : dict_gammapy[\"lightcurve\"][\"flux\"][i]   * 1e10,  # cm-2 s-1\n",
    "                \"e_flux\"    : dict_gammapy[\"lightcurve\"][\"e_flux\"][i] * 1e10,  # cm-2 s-1\n",
    "                \"timestamp\" : dict_gammapy[\"lightcurve\"][\"t_start\"][i],\n",
    "                \"duration\"  : dict_gammapy[\"lightcurve\"][\"timedelta\"][i]\n",
    "\n",
    "            }\n",
    "\n",
    "            dict_LC_run[run] = tmp_dict\n",
    "\n",
    "        dict_total = {}\n",
    "\n",
    "        dict_total[\"general\"] = {\n",
    "\n",
    "            \"target_name\"   : dict_gammapy[\"lightcurve\"][\"global\"][\"target_name\"],\n",
    "            \"e_min_lc\"      : dict_gammapy[\"lightcurve\"][\"global\"][\"e_min\"], # TeV\n",
    "            \"e_max_lc\"      : dict_gammapy[\"lightcurve\"][\"global\"][\"e_max\"], # TeV\n",
    "            \"n_off_regions\" : dict_gammapy[\"lightcurve\"][\"global\"][\"n_off_regions\"],\n",
    "            \"chi2_flux\"     : dict_gammapy[\"lightcurve\"][\"global\"][\"chi2\"],\n",
    "            \"pvalue_flux\"   : dict_gammapy[\"lightcurve\"][\"global\"][\"pvalue\"],\n",
    "            \"crab_reference_flux\" : dict_gammapy[\"lightcurve\"][\"global\"][\"crab_reference_flux\"].value * 1e10   \n",
    "\n",
    "        }\n",
    "\n",
    "        _ampl, _e_ampl = dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][0][\"value\"], dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][0][\"error\"]\n",
    "        _ampl_unit     = u.Unit(dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][0][\"unit\"])\n",
    "\n",
    "        _ref      = dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][1][\"value\"]\n",
    "        _ref_unit = u.Unit(dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][1][\"unit\"])\n",
    "\n",
    "        _a, _e_a = dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][2][\"value\"], dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][2][\"error\"]\n",
    "        _b, _e_b = dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][3][\"value\"], dict_gammapy[\"dict_model\"][\"spectral\"][\"parameters\"][3][\"error\"]\n",
    "\n",
    "        dict_total[\"general\"][\"model_params\"] = {\n",
    "\n",
    "                \"amplitude\" : (_ampl, _e_ampl) * _ampl_unit,\n",
    "                \"reference\" :  _ref * _ref_unit,\n",
    "                \"alpha\"     : (_a, _e_a),\n",
    "                \"beta\"      : (_b, _e_b)\n",
    "\n",
    "        }\n",
    "\n",
    "        dict_total[\"general\"][\"SED\"] = dict_gammapy[\"table_sed\"]\n",
    "\n",
    "\n",
    "        dict_total[\"run\"] = dict_LC_run\n",
    "\n",
    "        for run in np.sort(list(dict_dl2.keys())):\n",
    "\n",
    "            dict_total[\"run\"][run][\"zd\"]   = np.mean(dict_dl2[run][\"zd\"])\n",
    "            dict_total[\"run\"][run][\"e_zd\"] = (np.max(dict_dl2[run][\"zd\"]) - np.min(dict_dl2[run][\"zd\"])) / 2\n",
    "            dict_total[\"run\"][run][\"az\"]   = np.mean(dict_dl2[run][\"az\"])\n",
    "            dict_total[\"run\"][run][\"e_az\"] = (np.max(dict_dl2[run][\"az\"]) - np.min(dict_dl2[run][\"az\"])) / 2\n",
    "            dict_total[\"run\"][run][\"effective_time\"] = dict_dl2[run][\"effective_time\"]\n",
    "\n",
    "            counts, Iedges = np.histogram(np.log10(dict_dl2[run][\"intensity\"]), binsI)\n",
    "            counts   = counts / dict_dl2[run][\"effective_time\"]\n",
    "\n",
    "            dict_total[\"run\"][run][\"intensity_rates\"] = counts\n",
    "\n",
    "            dict_total[\"run\"][run][\"n_events\"] = len(dict_dl2[run][\"zd\"])\n",
    "\n",
    "        Icenters = (Iedges[1:] + Iedges[:-1]) / 2\n",
    "\n",
    "        dict_total[\"general\"][\"intensity_bins\"]         = Iedges\n",
    "        dict_total[\"general\"][\"intensity_bins_centers\"] = Icenters\n",
    "\n",
    "        # Saving the object\n",
    "        with open(fname_dict, 'wb') as f:\n",
    "            pickle.dump(dict_total, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fb2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For integration from 0.0100TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0104TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0107TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0111TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0115TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0119TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0123TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0128TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0132TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0137TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0141TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0146TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0152TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0157TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0163TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0168TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0174TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0180TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0187TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0193TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0200TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0207TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0215TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0222TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0230TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0238TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0247TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0255TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0264TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0274TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0283TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0293TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0304TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0314TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0326TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0337TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0349TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0361TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0374TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0387TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0401TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0415TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0430TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0445TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0461TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0477TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0494TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0511TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0529TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0548TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0567TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0587TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0608TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0629TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0652TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0675TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0699TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0723TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0749TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0775TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0803TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0831TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0860TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0891TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0922TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0955TeV to 50TeV, job failed to launch\n",
      "For integration from 0.0988TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1023TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1060TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1097TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1136TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1176TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1217TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1260TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1305TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1351TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1399TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1448TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1499TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1552TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1607TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1664TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1723TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1783TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1846TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1912TeV to 50TeV, job failed to launch\n",
      "For integration from 0.1979TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2049TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2121TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2196TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2274TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2354TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2437TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2524TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2613TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2705TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2801TeV to 50TeV, job failed to launch\n",
      "For integration from 0.2899TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3002TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3108TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3218TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3331TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3449TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3571TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3697TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3827TeV to 50TeV, job failed to launch\n",
      "For integration from 0.3963TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4103TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4248TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4398TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4553TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4714TeV to 50TeV, job failed to launch\n",
      "For integration from 0.4880TeV to 50TeV, job failed to launch\n",
      "For integration from 0.5053TeV to 50TeV, job failed to launch\n",
      "For integration from 0.5231TeV to 50TeV, job failed to launch\n",
      "For integration from 0.5416TeV to 50TeV, job failed to launch\n",
      "For integration from 0.5607TeV to 50TeV, job failed to launch\n",
      "For integration from 0.5805TeV to 50TeV, job failed to launch\n",
      "For integration from 0.6010TeV to 50TeV, job failed to launch\n",
      "For integration from 0.6223TeV to 50TeV, job failed to launch\n",
      "For integration from 0.6442TeV to 50TeV, job failed to launch\n",
      "For integration from 0.6670TeV to 50TeV, job failed to launch\n",
      "For integration from 0.6906TeV to 50TeV, job failed to launch\n",
      "For integration from 0.7149TeV to 50TeV, job failed to launch\n",
      "For integration from 0.7402TeV to 50TeV, job failed to launch\n",
      "For integration from 0.7663TeV to 50TeV, job failed to launch\n",
      "For integration from 0.7934TeV to 50TeV, job failed to launch\n",
      "For integration from 0.8214TeV to 50TeV, job failed to launch\n",
      "For integration from 0.8504TeV to 50TeV, job failed to launch\n",
      "For integration from 0.8805TeV to 50TeV, job failed to launch\n",
      "For integration from 0.9116TeV to 50TeV, job failed to launch\n",
      "For integration from 0.9438TeV to 50TeV, job failed to launch\n",
      "For integration from 0.9771TeV to 50TeV, job failed to launch\n",
      "For integration from 1.0116TeV to 50TeV, job failed to launch\n",
      "For integration from 1.0474TeV to 50TeV, job failed to launch\n",
      "For integration from 1.0844TeV to 50TeV, job failed to launch\n",
      "For integration from 1.1227TeV to 50TeV, job failed to launch\n",
      "For integration from 1.1623TeV to 50TeV, job failed to launch\n",
      "For integration from 1.2034TeV to 50TeV, job failed to launch\n",
      "For integration from 1.2459TeV to 50TeV, job failed to launch\n",
      "For integration from 1.2899TeV to 50TeV, job failed to launch\n",
      "For integration from 1.3355TeV to 50TeV, job failed to launch\n",
      "For integration from 1.3826TeV to 50TeV, job failed to launch\n",
      "For integration from 1.4315TeV to 50TeV, job failed to launch\n",
      "For integration from 1.4820TeV to 50TeV, job failed to launch\n",
      "For integration from 1.5344TeV to 50TeV, job failed to launch\n",
      "For integration from 1.5886TeV to 50TeV, job failed to launch\n",
      "For integration from 1.6447TeV to 50TeV, job failed to launch\n",
      "For integration from 1.7028TeV to 50TeV, job failed to launch\n",
      "For integration from 1.7629TeV to 50TeV, job failed to launch\n",
      "For integration from 1.8252TeV to 50TeV, job failed to launch\n",
      "For integration from 1.8897TeV to 50TeV, job failed to launch\n",
      "For integration from 1.9564TeV to 50TeV, job failed to launch\n",
      "For integration from 2.0255TeV to 50TeV, job failed to launch\n",
      "For integration from 2.0970TeV to 50TeV, job failed to launch\n",
      "For integration from 2.1711TeV to 50TeV, job failed to launch\n",
      "For integration from 2.2478TeV to 50TeV, job failed to launch\n",
      "For integration from 2.3272TeV to 50TeV, job failed to launch\n",
      "For integration from 2.4094TeV to 50TeV, job failed to launch\n",
      "For integration from 2.4945TeV to 50TeV, job failed to launch\n",
      "For integration from 2.5826TeV to 50TeV, job failed to launch\n",
      "For integration from 2.6738TeV to 50TeV, job failed to launch\n",
      "For integration from 2.7683TeV to 50TeV, job failed to launch\n",
      "For integration from 2.8661TeV to 50TeV, job failed to launch\n",
      "For integration from 2.9673TeV to 50TeV, job failed to launch\n",
      "For integration from 3.0721TeV to 50TeV, job failed to launch\n",
      "For integration from 3.1806TeV to 50TeV, job failed to launch\n",
      "For integration from 3.2930TeV to 50TeV, job failed to launch\n",
      "For integration from 3.4093TeV to 50TeV, job failed to launch\n",
      "For integration from 3.5297TeV to 50TeV, job failed to launch\n",
      "For integration from 3.6544TeV to 50TeV, job failed to launch\n",
      "For integration from 3.7835TeV to 50TeV, job failed to launch\n",
      "For integration from 3.9171TeV to 50TeV, job failed to launch\n",
      "For integration from 4.0555TeV to 50TeV, job failed to launch\n",
      "For integration from 4.1987TeV to 50TeV, job failed to launch\n",
      "For integration from 4.3470TeV to 50TeV, job failed to launch\n",
      "For integration from 4.5006TeV to 50TeV, job failed to launch\n",
      "For integration from 4.6595TeV to 50TeV, job failed to launch\n",
      "For integration from 4.8241TeV to 50TeV, job failed to launch\n",
      "For integration from 4.9945TeV to 50TeV, job failed to launch\n",
      "For integration from 5.1709TeV to 50TeV, job failed to launch\n",
      "For integration from 5.3536TeV to 50TeV, job failed to launch\n",
      "For integration from 5.5427TeV to 50TeV, job failed to launch\n",
      "For integration from 5.7384TeV to 50TeV, job failed to launch\n",
      "For integration from 5.9411TeV to 50TeV, job failed to launch\n",
      "For integration from 6.1510TeV to 50TeV, job failed to launch\n",
      "For integration from 6.3682TeV to 50TeV, job failed to launch\n",
      "For integration from 6.5932TeV to 50TeV, job failed to launch\n",
      "For integration from 6.8261TeV to 50TeV, job failed to launch\n",
      "For integration from 7.0672TeV to 50TeV, job failed to launch\n",
      "For integration from 7.3168TeV to 50TeV, job failed to launch\n",
      "For integration from 7.5753TeV to 50TeV, job failed to launch\n",
      "For integration from 7.8428TeV to 50TeV, job failed to launch\n",
      "For integration from 8.1198TeV to 50TeV, job failed to launch\n",
      "For integration from 8.4067TeV to 50TeV, job failed to launch\n",
      "For integration from 8.7036TeV to 50TeV, job failed to launch\n",
      "For integration from 9.0110TeV to 50TeV, job failed to launch\n",
      "For integration from 9.3293TeV to 50TeV, job failed to launch\n",
      "For integration from 9.6588TeV to 50TeV, job failed to launch\n",
      "For integration from 10.0000TeV to 50TeV, job failed to launch\n"
     ]
    }
   ],
   "source": [
    "for double in a_lcs:\n",
    "\n",
    "    # Energy LC limits\n",
    "    e_lc_min, e_lc_max = double\n",
    "    \n",
    "    fname_dict_sed_lc = os.path.join(folder_dirs_sed_lc, f\"dict_{e_lc_min:.3f}_{int(e_lc_max)}.pkl\")\n",
    "    \n",
    "    if not os.path.exists(fname_dict_sed_lc):\n",
    "        print(f\"For integration from {e_lc_min:.4f}TeV to {int(e_lc_max)}TeV, job failed to launch\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
