{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4152cd21",
   "metadata": {},
   "source": [
    "# Convert dl2 to dl3\n",
    "\n",
    "First of all we import packages and create the logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf44c3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, json, glob, logging\n",
    "\n",
    "from traitlets.config.loader import Config\n",
    "from lstchain.io.config import read_configuration_file\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# import scripts\n",
    "sys.path.insert(0, os.path.join(\"/fefs/aswg/workspace/juan.jimenez/lst1_systematics/scripts\"))\n",
    "import auxiliar as aux\n",
    "\n",
    "# logging definition\n",
    "try:\n",
    "    logger\n",
    "except NameError:\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.addHandler(logging.StreamHandler())\n",
    "    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e980ce",
   "metadata": {},
   "source": [
    "Defining all paths and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b224744",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EventSelector': {'filters': {'intensity': [80, inf],\n",
       "   'width': [0, inf],\n",
       "   'length': [0, inf],\n",
       "   'r': [0, 1],\n",
       "   'wl': [0, 1],\n",
       "   'leakage_intensity_width_2': [0, 1],\n",
       "   'event_type': [32, 32]}},\n",
       " 'DL3Cuts': {'min_event_p_en_bin': 100,\n",
       "  'min_gh_cut': 0.1,\n",
       "  'max_gh_cut': 0.95,\n",
       "  'min_theta_cut': 0.05,\n",
       "  'max_theta_cut': 0.32,\n",
       "  'fill_theta_cut': 0.32,\n",
       "  'allowed_tels': [1]},\n",
       " 'DataBinning': {'true_energy_min': 0.002,\n",
       "  'true_energy_max': 200,\n",
       "  'true_energy_n_bins_per_decade': 5,\n",
       "  'reco_energy_min': 0.002,\n",
       "  'reco_energy_max': 200,\n",
       "  'reco_energy_n_bins_per_decade': 5,\n",
       "  'energy_migration_min': 0.2,\n",
       "  'energy_migration_max': 5,\n",
       "  'energy_migration_n_bins': 31,\n",
       "  'fov_offset_min': 0.1,\n",
       "  'fov_offset_max': 1.1,\n",
       "  'fov_offset_n_edges': 9,\n",
       "  'bkg_fov_offset_min': 0,\n",
       "  'bkg_fov_offset_max': 10,\n",
       "  'bkg_fov_offset_n_edges': 21,\n",
       "  'source_offset_min': 0.0001,\n",
       "  'source_offset_max': 1.0001,\n",
       "  'source_offset_n_edges': 1000}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################\n",
    "# Paths and directories\n",
    "root_dl2 = \"/fefs/aswg/workspace/abelardo.moralejo/Crab_performance_paper/data_v0.9.9/DL2/\"\n",
    "root_mc  = \"/fefs/aswg/data/mc/DL2/AllSky/20221027_v0.9.9_crab_tuned/TestingDataset/dec_2276/\"\n",
    "\n",
    "path_irf    = \"/fefs/aswg/workspace/juan.jimenez/data/lst1_systematics/irf\"\n",
    "path_dl3    = \"/fefs/aswg/workspace/juan.jimenez/data/lst1_systematics/dl3\"\n",
    "\n",
    "config_file = \"/fefs/aswg/workspace/juan.jimenez/lst1_systematics/config/dl2_dl3_config.json\"\n",
    "\n",
    "# output name\n",
    "fname_dict = \"objects/dict_dl2_dl3_MCs.json\"\n",
    "\n",
    "\n",
    "######################################\n",
    "# Avoid repeating long processes\n",
    "compute_irf    = True\n",
    "compute_dl3    = True\n",
    "\n",
    "######################################\n",
    "# Source info\n",
    "source_name = \"Crab\"\n",
    "\n",
    "######################################\n",
    "# Reading the configuration file\n",
    "config = Config(read_configuration_file(config_file))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c57376",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux.createdir(path_irf)\n",
    "aux.createdir(path_dl3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b58b5",
   "metadata": {},
   "source": [
    "Creating a dictionary with all runs and the dl2 directory, and theta and az of the MC used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b22d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders if do not exist\n",
    "aux.createdir(path_irf)\n",
    "aux.createdir(path_dl3)\n",
    "\n",
    "# --- Opening all files in the root path filtering that contain the words \"process\" in the dir --- #\n",
    "items_in_root = os.listdir(root_dl2)\n",
    "dirs_dl2 = [item for item in items_in_root if os.path.isdir(os.path.join(root_dl2, item)) if \"process\" in item]\n",
    "dirs_dl2 = np.sort([os.path.join(root_dl2, d) for d in dirs_dl2])\n",
    "\n",
    "logger.info(f\"Searching for DL2 files at:\\n{root_dl2}\\n\\nFound {len(dirs_dl2)} folders i.e. {len(dirs_dl2)} different MC used\")\n",
    "\n",
    "dict_runs = {}\n",
    "# Looping over all folders\n",
    "for i in range(len(dirs_dl2)):\n",
    "        \n",
    "        # Now we find the files inside each folder and keep only \".h5\" files\n",
    "        _files_ = os.listdir(dirs_dl2[i])\n",
    "        _files_ = [os.path.join(dirs_dl2[i], f.decode('utf-8')) for f in _files_ if \".h5\" in str(f)]\n",
    "        # Extract run numbers\n",
    "        run_nums = [int(f[-8:-3]) for f in _files_]    \n",
    "        \n",
    "        # Iterate over all files in each directory\n",
    "        for j in range(len(_files_)):\n",
    "            \n",
    "            # Creating a sub-dict for each run\n",
    "            tmp_dict = {}\n",
    "            tmp_dict[\"dl2\"] = _files_[j]\n",
    "            tmp_dict[\"irf\"] = os.path.join(path_irf, f\"irf_{os.path.basename(dirs_dl2[i])[13:]}.fits.gz\")\n",
    "            \n",
    "            dict_runs[int(run_nums[j])] = tmp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22799a2",
   "metadata": {},
   "source": [
    "Now we need to create the IRFs for all the MC files in the MC directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4970f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correspondence between MC folder and MC file\n",
    "dict_dirs_mc = {\n",
    "    \"process_with_mc_theta_10.0_az_102.199\"   : \"node_theta_10.0_az_102.199_/dl2_20221027_v0.9.9_crab_tuned_node_theta_10.0_az_102.199__merged.h5\",\n",
    "    \"process_with_mc_theta_10.0_az_248.117\"   : \"node_theta_10.0_az_248.117_/dl2_20221027_v0.9.9_crab_tuned_node_theta_10.0_az_248.117__merged.h5\",\n",
    "    \"process_with_mc_theta_23.63_az_100.758\"  : \"node_theta_23.630_az_100.758_/dl2_20221027_v0.9.9_crab_tuned_node_theta_23.630_az_100.758__merged.h5\",\n",
    "    \"process_with_mc_theta_23.63_az_259.265\"  : \"node_theta_23.630_az_259.265_/dl2_20221027_v0.9.9_crab_tuned_node_theta_23.630_az_259.265__merged.h5\",\n",
    "    \"process_with_mc_theta_32.059_az_102.217\" : \"node_theta_32.059_az_102.217_/dl2_20221027_v0.9.9_crab_tuned_node_theta_32.059_az_102.217__merged.h5\",\n",
    "    \"process_with_mc_theta_32.059_az_248.099\" : \"node_theta_32.059_az_248.099_/dl2_20221027_v0.9.9_crab_tuned_node_theta_32.059_az_248.099__merged.h5\",\n",
    "}\n",
    "\n",
    "\n",
    "for key in dict_dirs_mc.keys():\n",
    "    \n",
    "    logger.info(f\"Creating IRF for {key[13:]}\")\n",
    "    \n",
    "    mc_input   = os.path.join(root_mc, dict_dirs_mc[key])\n",
    "    irf_output = os.path.join(path_irf, f\"irf_{key[13:]}.fits.gz\")\n",
    "    logger.debug(f\"\\n{os.path.basename(mc_input)} --> {os.path.basename(irf_output)}\")\n",
    "    \n",
    "    if compute_irf:\n",
    "                \n",
    "        # Creating the IRF\n",
    "        !lstchain_create_irf_files \\\n",
    "        --input-gamma-dl2 $mc_input \\\n",
    "        --output-irf-file $irf_output \\\n",
    "        --point-like \\\n",
    "        --overwrite    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06841f",
   "metadata": {},
   "source": [
    "At the end we create the dl3 file from the dl2 file and the corresponding irf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13894191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the irf directory to the dict\n",
    "for run in dict_runs.keys():\n",
    "    dict_runs[run][\"dl3\"] = os.path.join(path_dl3, f\"dl3_LST-1.Run{run:05}.fits.gz\")\n",
    "    \n",
    "# Iterate over all dl2 files\n",
    "for i, run in enumerate(dict_runs.keys()):\n",
    "\n",
    "    # filenames of dl2 and irf\n",
    "    input_dl2 = dict_runs[run][\"dl2\"]\n",
    "    input_irf = dict_runs[run][\"irf\"]\n",
    "    logger.debug(f\"\\n{os.path.basename(input_dl2)} + {os.path.basename(input_irf)} --> dl3\")\n",
    "    \n",
    "    if compute_dl3:\n",
    "            \n",
    "        logger.info(f\"Computing dl3 for Run{run},  {i/len(dict_runs)*100:.1f}%...\")\n",
    "\n",
    "        # Creating the dl3\n",
    "        !lstchain_create_dl3_file \\\n",
    "        --input-dl2 $input_dl2 \\\n",
    "        --input-irf $input_irf \\\n",
    "        --output-dl3-path $path_dl3 \\\n",
    "        --source-name $source_name \\\n",
    "        --source-ra=$source_ra \\\n",
    "        --source-dec=$source_dec \\\n",
    "        --config $config_file \\\n",
    "        --overwrite\n",
    "                  \n",
    "if compute_dl3:\n",
    "    \n",
    "    logger.info(f\"All dl3 files created 100%\\n\\n\\nCreating index files...\")\n",
    "    \n",
    "    # Creating the index file\n",
    "    !lstchain_create_dl3_index_files \\\n",
    "    --input-dl3-dir $path_dl3 \\\n",
    "    --file-pattern 'dl3*.fits' \\\n",
    "    --overwrite\n",
    "                  \n",
    "    logger.info(f\"Finished with the dl3 process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8694f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dict to a external object \n",
    "if compute_dl3:\n",
    "    file = open(fname_dict, \"w\")\n",
    "    json.dump(dict_runs, file)\n",
    "    file.close()\n",
    "else:\n",
    "    with open(fname_dict, \"r\") as json_file:\n",
    "        dict_runs = json.load(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
